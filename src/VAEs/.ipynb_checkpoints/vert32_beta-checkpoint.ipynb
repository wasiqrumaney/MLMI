{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_ID = '32a_01'\n",
    "USE_TBX = False\n",
    "COEFF_REC = 1\n",
    "COEFF_KLD = 1\n",
    "objective = 'H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils import plot_3d_mesh, VertDataset, ResizeTo\n",
    "import utils as ut\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paramaters\n",
    "VOL_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 1e-3\n",
    "LOG_INTERVAL = 3\n",
    "\n",
    "N = 1    # = None # for full dataset\n",
    "BATCH_SIZE = 64\n",
    "Z_DIMS = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_path = pathlib.Path(\"./for_VAE/npz\")\n",
    "\n",
    "# beta = torch.tensor(4.0, requires_grad=True).float().to(device)\n",
    "\n",
    "if USE_TBX:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    #SummaryWriter encapsulates everything\n",
    "    log_dir = pathlib.Path('./logs/%s' % TRIAL_ID)\n",
    "    writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  1\n",
      "Number of batches:  1\n"
     ]
    }
   ],
   "source": [
    "dataset = VertDataset(train_path,n=N, transform=transforms.Compose([ResizeTo(VOL_SIZE),\n",
    "                                                               transforms.ToTensor()]))\n",
    "print('Number of samples: ',len(dataset))\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print('Number of batches: ',len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x = dataset[0]\n",
    "# print(x.size())\n",
    "# print(x.unique())\n",
    "# plot_3d_mesh(x)\n",
    "# del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from vae32 import Vae32 as VAE\n",
    "from vae32 import Vae32_v2 as VAE\n",
    "\n",
    "# model = VAE(debug=False).to(device)\n",
    "model = VAE(debug=False, z_dim=Z_DIMS).to(device)\n",
    "weights_init = ut.init_weights(init_type='normal')\n",
    "model.apply(weights_init)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta\n",
      "encoder.0.weight\n",
      "encoder.0.bias\n",
      "encoder.2.weight\n",
      "encoder.2.bias\n",
      "encoder.4.weight\n",
      "encoder.4.bias\n",
      "encoder.6.weight\n",
      "encoder.6.bias\n",
      "encoder.8.weight\n",
      "encoder.8.bias\n",
      "encoder.10.weight\n",
      "encoder.10.bias\n",
      "decoder.1.weight\n",
      "decoder.1.bias\n",
      "decoder.3.weight\n",
      "decoder.3.bias\n",
      "decoder.5.weight\n",
      "decoder.5.bias\n",
      "decoder.7.weight\n",
      "decoder.7.bias\n",
      "decoder.9.weight\n",
      "decoder.9.bias\n",
      "decoder.11.weight\n",
      "decoder.11.bias\n"
     ]
    }
   ],
   "source": [
    "for name, data in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(x, x_recon, distribution='gaussian'):\n",
    "    batch_size = x.size(0)\n",
    "    assert batch_size != 0\n",
    "\n",
    "#     x_recon = F.sigmoid(x_recon)\n",
    "    recon_loss = F.mse_loss(x_recon, x, size_average=False).div(batch_size)\n",
    "\n",
    "    return recon_loss\n",
    "\n",
    "def kl_divergence(mu, logvar):\n",
    "    batch_size = mu.size(0)\n",
    "    assert batch_size != 0\n",
    "    if mu.data.ndimension() == 4:\n",
    "        mu = mu.view(mu.size(0), mu.size(1))\n",
    "    if logvar.data.ndimension() == 4:\n",
    "        logvar = logvar.view(logvar.size(0), logvar.size(1))\n",
    "\n",
    "    klds = -0.5*(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    total_kld = klds.sum(1).mean(0, True)\n",
    "    dimension_wise_kld = klds.mean(0)\n",
    "    mean_kld = klds.mean(1).mean(0, True)\n",
    "\n",
    "    return total_kld, dimension_wise_kld, mean_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\almco\\Anaconda3\\envs\\pt41\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning:\n",
      "\n",
      "size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'beta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5737a3a35be7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;36m100.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 beta.item(), recon_loss.item(), total_kld.item(), mean_kld.item(), loss.item() ))\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0miters\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m#Finished one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'beta' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "loss_history = list()\n",
    "iters=0\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start = time.time()\n",
    "################## TRAIN ########################\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = data\n",
    "        recon_batch, mu, logvar = model(x)\n",
    "\n",
    "        recon_loss = reconstruction_loss(x, recon_batch)\n",
    "        total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, logvar)    \n",
    "\n",
    "        loss = recon_loss + model.beta * total_kld\n",
    "    \n",
    "        loss.backward()\n",
    "        loss_history.append( loss.item() )\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {:02d} [{:04d}/{:04d} ({:.0f}%)]\\tBeta: {:.4f}, Rec: {:.4f}, TotKLD: {:.4f}, MeanKLD: {:.5f}, Loss: {:.5f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                model.beta.item(), recon_loss.item(), total_kld.item(), mean_kld.item(), loss.item() ))\n",
    "        iters+=1\n",
    "    #Finished one epoch        \n",
    "    print('====> Epoch: {:02d} Average loss: {:.5f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    print('Training time for epoch: {:.2f}s'.format(end-start))\n",
    "        \n",
    "    print('======================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss\n",
    "SHOW_FROM = 0\n",
    "plt.plot(loss_history[SHOW_FROM:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check reconstruction\n",
    "inbatch_idx = 0\n",
    "with torch.no_grad():\n",
    "    x = next(iter(train_loader))\n",
    "    x = x.to(device)\n",
    "    recon_x, _, _ = model(x)\n",
    "    \n",
    "    plot_3d_mesh(x[inbatch_idx])\n",
    "    plot_3d_mesh(recon_x[inbatch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CHECK GENERATION RESULTS\n",
    "print('Generating samples')\n",
    "N_samples = 20\n",
    "with torch.no_grad():\n",
    "    z_samples = torch.randn(N_samples, Z_DIMS).to(device)\n",
    "    samples = model.decode(z_samples)\n",
    "        \n",
    "for x in samples:\n",
    "        plot_3d_mesh(x)\n",
    "#     plot_3d_mesh(ut.do_threshold(x, eps=0.3))\n",
    "#     plot_3d_mesh(np.round(x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
